{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igl\n",
    "#import meshplot as mp\n",
    "import vedo as vd\n",
    "import pandas as pd \n",
    "import polyscope as ps\n",
    "import numpy as np\n",
    "import os \n",
    "import time \n",
    "from geometry.mesh import Mesh\n",
    "from geometry.utils import *\n",
    "from optimization.Planarity import Planarity\n",
    "from optimization.HyperbolicLC import HyperbolicLC\n",
    "from optimization.Optimizer import Optimizer\n",
    "from optimization.LineCong import LineCong\n",
    "\n",
    "# Define paths\n",
    "dir_path = os.getcwd()\n",
    "data_path = dir_path+\"/approximation/data/\" # data path\n",
    "out_path = dir_path+\"/outputs/\" # output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unormalize_dir(h_pts, dual, inner_vertices, tv, e_i, rad):\n",
    "    \"\"\"Input \n",
    "        h_pts: sphere centers\n",
    "        e_i: edge directions normalized\n",
    "        rad: sphere radii\n",
    "        Ouput:\n",
    "        le: unormalized edge directions\n",
    "\n",
    "    \"\"\"\n",
    "    # factors\n",
    "    l = np.ones(len(e_i))\n",
    "    for i in range(len(inner_vertices)):\n",
    "        # Get dual faces index\n",
    "        idx = inner_vertices[i]\n",
    "   \n",
    "        # Get dual face\n",
    "        f = dual[idx]\n",
    "        \n",
    "        # Get sphere centers\n",
    "        p = h_pts[f]\n",
    "        \n",
    "        # Get edge direction\n",
    "        e = e_i[idx]\n",
    "\n",
    "        # Get radius\n",
    "        r = rad[idx]\n",
    "\n",
    "        # Direction from v_i to center\n",
    "        dc = p - tv[idx]\n",
    "        dc /= np.linalg.norm(dc, axis=1)[:, None] # normalize\n",
    "        \n",
    "        # cos angle e_i with the direction to the center\n",
    "        theta = np.sum(e*dc, axis=1)\n",
    "\n",
    "        # Get the lambdaz\n",
    "        l[idx] = np.mean(2*r*theta)\n",
    "        \n",
    "    # unormalize\n",
    "    le = e_i*l[:, None]\n",
    "    return le\n",
    "\n",
    "def init_test_data(data):\n",
    "    # # Define paths\n",
    "    dir_path = os.getcwd()\n",
    "    data_path = dir_path+\"/approximation/data/\" # data path\n",
    "\n",
    "    # Data of interest\n",
    "    k = data\n",
    "\n",
    "    # Load M mesh (centers of sphere mesh)\n",
    "    mv, mf = igl.read_triangle_mesh( os.path.join(data_path ,\"centers.obj\") ) \n",
    "\n",
    "    # Load test mesh\n",
    "    tv, tf = igl.read_triangle_mesh(os.path.join(data_path,  \"test_remeshed_\"+str(k)+\".obj\"))\n",
    "\n",
    "    # Create dual mesh\n",
    "    tmesh = Mesh()\n",
    "    tmesh.make_mesh(tv,tf)\n",
    "\n",
    "    # Get inner vertices\n",
    "    inner_vertices = tmesh.inner_vertices()\n",
    "\n",
    "    # Get vertex normals for test mesh\n",
    "    e_i = igl.per_vertex_normals(tv, tf)\n",
    "\n",
    "    # Fix normal directions\n",
    "    signs = np.sign(np.sum(e_i * ([0,0,1]), axis=1))\n",
    "    e_i = e_i * signs[:, None]\n",
    "\n",
    "    # Compute circumcenters and axis vectors for each triangle\n",
    "    p1, p2, p3 = tv[tf[:, 0]], tv[tf[:, 1]], tv[tf[:, 2]]\n",
    "\n",
    "    ct, _, nt = circle_3pts(p1, p2, p3)\n",
    "\n",
    "    # Dual topology \n",
    "    dual_tf = tmesh.vertex_ring_faces_list()\n",
    "\n",
    "    # Create hexagonal mesh                            \n",
    "    h_pts = np.empty((len(tf), 3), dtype=np.float64)\n",
    "    center = vd.Mesh((mv, mf), alpha = 0.9, c=[0.4, 0.4, 0.81])\n",
    "\n",
    "    # Intersect circumcircle axis with center mesh\n",
    "    for i in range(len(tf)):\n",
    "        # Get points on circumcircle axis\n",
    "        p0  = ct[i] - 10*nt[i]\n",
    "        p1  = ct[i] + 10*nt[i]\n",
    "        \n",
    "        # Get intersection points\n",
    "        h_pts[i,:] = np.array(center.intersect_with_line(p0, p1)[0])\n",
    "\n",
    "    # Get radius of spheres\n",
    "    r = np.linalg.norm(h_pts - tv[tf[:,0]], axis=1)\n",
    "\n",
    "    return tv, tf, inner_vertices, e_i, h_pts, dual_tf, r \n",
    "\n",
    "\n",
    "def compute_disc(tv, tf, e_i):\n",
    "\n",
    "    # # Compute the edge vectors per each face\n",
    "    vi, vj, vk = tv[tf[:,0]], tv[tf[:,1]], tv[tf[:,2]]\n",
    "\n",
    "    # # Compute the edge vectors per each face\n",
    "    vij = vj - vi\n",
    "    vik = vk - vi\n",
    "\n",
    "    # Set up X \n",
    "    eij = e_i[tf[:,1]] - e_i[tf[:,0]]\n",
    "    eik = e_i[tf[:,2]] - e_i[tf[:,0]]\n",
    "\n",
    "    ec = np.sum( e_i[tf], axis = 1) / 3\n",
    "\n",
    "    # A = [vij, eik, ec] + [eij, vik, ec], where [ , , ] denotes determinant\n",
    "    # A = gamma11 +  gamma12\n",
    "    eikXec = np.cross(eik, ec)\n",
    "    vikXec = np.cross(vik, ec)\n",
    "\n",
    "    det1 = np.sum(vij*eikXec, axis=1)\n",
    "    det2 = np.sum(eij*vikXec, axis=1)\n",
    "\n",
    "    # b = [eij, eik, ec]  c = [vij, vik, ec]\n",
    "\n",
    "    gamma0 = np.sum(eij*eikXec, axis=1)\n",
    "    gamma2 = np.sum(vij*vikXec, axis=1)\n",
    "\n",
    "    A = det1 + det2 \n",
    "\n",
    "    return A, A**2 - 4*gamma0*gamma2\n",
    "\n",
    "def unormalize_dir(h_pts, dual, inner_vertices, tv, e_i, rad):\n",
    "    \"\"\"Input \n",
    "        h_pts: sphere centers\n",
    "        e_i: edge directions normalized\n",
    "        rad: sphere radii\n",
    "        Ouput:\n",
    "        le: unormalized edge directions\n",
    "\n",
    "    \"\"\"\n",
    "    le = np.ones_like(e_i)\n",
    "    for i in range(len(inner_vertices)):\n",
    "        # Get dual faces index\n",
    "        idx = inner_vertices[i]\n",
    "\n",
    "        # Get dual face\n",
    "        f = dual[idx]\n",
    "\n",
    "        # Get sphere centers\n",
    "        p = h_pts[f]\n",
    "\n",
    "        # Get edge direction\n",
    "        e = e_i[idx]\n",
    "\n",
    "        # Get radius\n",
    "        r = rad[idx]\n",
    "\n",
    "        # angle e_i with the direction to the center\n",
    "        theta = np.arccos(np.sum(e*(p - tv[idx]), axis=1))\n",
    "\n",
    "        print(theta)\n",
    "\n",
    "        # Get the lambda\n",
    "        le[idx] = 2*r*np.cos(theta)\n",
    "\n",
    "    return le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LC + Hyp energy Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh Data Structure: |V| = 1659, |F| = 3171, |E| = 4829\n",
      " E 1: 3472.4230536700006\n",
      " E 2: 1079.807646955132\n",
      " E 3: 336.93556708371284\n",
      " E 4: 105.80503265158106\n",
      " E 5: 33.62082382868519\n",
      " E 6: 11.01720978567038\n",
      " E 7: 3.9245360939743623\n",
      " E 8: 1.695374359856471\n",
      " E 9: 0.993913700076041\n",
      " E 10: 0.7729931077654261\n",
      " E 11: 0.7033828919503261\n",
      " E 12: 0.6814490235208466\n",
      " E 13: 0.6745416615164265\n",
      " E 14: 0.6723691385804018\n"
     ]
    }
   ],
   "source": [
    "# Init data \n",
    "tv, tf, inner_vertices, e_i, h_pts, dual_tf, r = init_test_data(4)\n",
    "\n",
    "# variables = [e_i | A| delta]; e_i direction per vertex in T and A is one per each triangle in T, same for delta \n",
    "X = np.zeros(3*len(tv) + 2*len(tf) )\n",
    "\n",
    "# Init directions\n",
    "X[:3*len(tv)] = e_i.flatten()\n",
    "\n",
    "# Init LineCong\n",
    "linecong = LineCong()\n",
    "linecong.initialize_constraint(X, len(tv), h_pts, dual_tf, inner_vertices, 1)\n",
    "\n",
    "# # Init Hyperbolic\n",
    "hyp = HyperbolicLC()\n",
    "X = hyp.initialize_constraint(X, tv, tf, e_i, 1, 1)\n",
    "\n",
    "# Init optimizer\n",
    "opt = Optimizer()\n",
    "opt.initialize_optimizer(X)\n",
    "\n",
    "# Time tracker\n",
    "time_opt = []\n",
    "\n",
    "for i in range(14):\n",
    "\n",
    "    # Take time\n",
    "    start = time.time()\n",
    "\n",
    "    # Compute J, r per energy\n",
    "    hyp.compute(X, tf)\n",
    "    linecong.compute(X, inner_vertices, dual_tf)\n",
    "\n",
    "    # Add constraints to optimizer\n",
    "    opt.add_constraint(hyp)\n",
    "    opt.add_constraint(linecong)\n",
    "\n",
    "    # Optimize\n",
    "    opt.optimize(\"LM\")\n",
    "\n",
    "    # Take time\n",
    "    end = time.time()\n",
    "\n",
    "    # Update X\n",
    "    X = opt.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_i = opt.X[:3*len(tv)].reshape(len(tv), 3)\n",
    "e_i /= np.linalg.norm(e_i, axis=1)[:, None]\n",
    "\n",
    "#le = unormalize_dir(h_pts, dual_tf, inner_vertices, tv, e_i, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_torsal_direction(data, tv, tf, e_i):\n",
    "\n",
    "    # Data \n",
    "    k = data\n",
    "\n",
    "    # Create file for positions\n",
    "    pos = open(os.path.join( out_path, \"torsal_pos_\"+str(k)+\".dat\"), \"w\")\n",
    "    # Create file for torsal directions\n",
    "    tdir = open(os.path.join( out_path, \"torsal_dir_\"+str(k)+\".dat\"), \"w\")\n",
    "    # Create file to store the ids of the inner faces\n",
    "    f_if = open(os.path.join( out_path, \"inner_faces_\"+str(k)+\".dat\"), \"w\")\n",
    "\n",
    "    # Compute torsal directions\n",
    "    barycenters, t1, t2, cos_tors = torsal_dir_vec(tv, tf, e_i)\n",
    "    \n",
    "    # Get inner faces\n",
    "    t_mesh = Mesh()\n",
    "    t_mesh.make_mesh(tv, tf)\n",
    "    inner_faces = t_mesh.inner_faces()\n",
    "\n",
    "    for ii in range(len(inner_faces)):\n",
    "        i = inner_faces[ii]\n",
    "        pos.write(str(barycenters[i][0]) + \" \" + str(barycenters[i][1]) + \" \" + str(barycenters[i][2]) + \"\\n\")\n",
    "        tdir.write(str(t1[i][0]) + \" \" + str(t1[i][1]) + \" \" + str(t1[i][2]) + \" \" + str(t2[i][0]) + \" \" + str(t2[i][1]) + \" \" + str(t2[i][2]) + \"\\n\")\n",
    "        f_if.write(str(i) + \"\\n\")\n",
    "\n",
    "\n",
    "    pos.close()\n",
    "    print(\"Positions file created\")\n",
    "    tdir.close()\n",
    "    print(\"Torsal dir files created\")\n",
    "    f_if.close()\n",
    "    print(\"Inner faces file created\")\n",
    "\n",
    "def export_toral_data_testing(data, tv, tf, e_i, list_bad_faces):\n",
    "\n",
    "    # Data\n",
    "    k = data \n",
    "\n",
    "    # Compute torsal directions\n",
    "    _, t1, t2, _ = torsal_dir_vec(tv, tf, e_i)\n",
    "\n",
    "    # Create data frame\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Create a table with e_i[tf[list_bad_faces]], tv[tf[list_bad_Faces]], t1[list_bad_faces], t2[list_bad_faces]\n",
    "    df[\"e_i\"] = e_i[tf[list_bad_faces]].tolist()\n",
    "    df[\"tv\"] = tv[tf[list_bad_faces]].tolist()\n",
    "    df[\"t1\"] = t1[list_bad_faces].tolist()\n",
    "    df[\"t2\"] = t2[list_bad_faces].tolist()\n",
    "\n",
    "    # Export df to csv\n",
    "    df.to_csv(os.path.join( out_path, \"bf_data_\"+str(k)+\".csv\"), index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh Data Structure: |V| = 1659, |F| = 3171, |E| = 4829\n",
      "Positions file created\n",
      "Torsal dir files created\n",
      "Inner faces file created\n"
     ]
    }
   ],
   "source": [
    "export_torsal_direction(4, tv, tf, e_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_toral_data_testing(4, tv, tf, e_i, np.array([847,833,806,776,770,767,733,721,688,571]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hananJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
