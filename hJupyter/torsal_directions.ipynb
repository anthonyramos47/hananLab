{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igl\n",
    "#import meshplot as mp\n",
    "import polyscope as ps\n",
    "import vedo as vd\n",
    "import numpy as np\n",
    "import time \n",
    "import os\n",
    "from geometry.mesh import Mesh\n",
    "from geometry.utils import *\n",
    "from optimization.Torsal import Torsal\n",
    "from optimization.Optimizer import Optimizer\n",
    "from optimization.LineCong import LineCong\n",
    "\n",
    "# Define paths\n",
    "dir_path = os.getcwd()\n",
    "data_path = dir_path+\"/approximation/data/\" # data path\n",
    "out_path = dir_path+\"/outputs/\" # output path\n",
    "math_path = dir_path+\"/mathematica/\" # mathematica path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def solve_torsal(vi, vj, vk, ei, ej, ek) :\n",
    "\n",
    "    # Get edges\n",
    "    vij = vj - vi \n",
    "    vik = vk - vi\n",
    "\n",
    "    eij = ej - ei \n",
    "    eik = ek - ei\n",
    "    \n",
    "\n",
    "    ec = (ei + ej + ek)/3\n",
    "\n",
    "    vijxec = np.cross(vij, ec)\n",
    "    vikxec = np.cross(vik, ec)\n",
    "\n",
    "    # g0 \n",
    "    g0 = np.sum(eij*vijxec, axis=1)\n",
    "\n",
    "    # g1\n",
    "    g1 = np.sum(eij*vikxec, axis=1) + np.sum(eik*vijxec, axis=1)\n",
    "\n",
    "    # g2\n",
    "    g2 = np.sum(eik*vikxec, axis=1)\n",
    "\n",
    "\n",
    "    disc = g1**2 - 4*g0*g2 \n",
    "\n",
    "    t1 = np.zeros_like(vij)\n",
    "    t2 = np.zeros_like(vij)\n",
    "\n",
    "    a1 = np.zeros(len(vij))\n",
    "    a2 = np.zeros(len(vij))\n",
    "    b1 = np.zeros(len(vij))\n",
    "\n",
    "    # indices disc >0 \n",
    "    idx = np.where(disc > 0)[0]\n",
    "\n",
    "    a1[idx] = (-g1[idx] + np.sqrt(g1[idx]**2 - 4*g0[idx]*g2[idx]))\n",
    "    a2[idx] = (-g1[idx] - np.sqrt(g1[idx]**2 - 4*g0[idx]*g2[idx]))\n",
    "    b1[idx] = 2*g0[idx]\n",
    "\n",
    "    # sol\n",
    "    t1[idx] = (-g1[idx] + np.sqrt(g1[idx]**2 - 4*g0[idx]*g2[idx]))[:, None]*vij[idx] + 2*g0[idx,None]*vik[idx]\n",
    "    t2[idx] = (-g1[idx] - np.sqrt(g1[idx]**2 - 4*g0[idx]*g2[idx]))[:, None]*vij[idx] + 2*g0[idx,None]*vik[idx]\n",
    "\n",
    "    # Normalize\n",
    "    t1[idx] /= np.linalg.norm(t1[idx], axis=1)[:, None]\n",
    "    t2[idx] /= np.linalg.norm(t2[idx], axis=1)[:, None]\n",
    "\n",
    "    return t1, t2, a1, a2, b1 \n",
    "\n",
    "def vv_second(vvi, vvj, vvk, f, numV):\n",
    "\n",
    "    vv = np.zeros((numV, 3))\n",
    "\n",
    "    for i in range(len(f)):\n",
    "        vv[f[i,0]] = vvi[i]\n",
    "        vv[f[i,1]] = vvj[i]\n",
    "        vv[f[i,2]] = vvk[i]\n",
    "\n",
    "    return vv\n",
    "\n",
    "\n",
    "def init_test_data(data):\n",
    "    # # Define paths\n",
    "    dir_path = os.getcwd()\n",
    "    data_path = dir_path+\"/approximation/data/\" # data path\n",
    "\n",
    "    # Data of interest\n",
    "    k = data\n",
    "\n",
    "    # Load M mesh (centers of sphere mesh)\n",
    "    mv, mf = igl.read_triangle_mesh( os.path.join(data_path ,\"centers.obj\") ) \n",
    "\n",
    "    # Load test mesh\n",
    "    tv, tf = igl.read_triangle_mesh(os.path.join(data_path,  \"test_remeshed_\"+str(k)+\".obj\"))\n",
    "\n",
    "    # Create dual mesh\n",
    "    tmesh = Mesh()\n",
    "    tmesh.make_mesh(tv,tf)\n",
    "\n",
    "    # Get inner vertices\n",
    "    inner_vertices = tmesh.inner_vertices()\n",
    "\n",
    "    # Get vertex normals for test mesh\n",
    "    e_i = igl.per_vertex_normals(tv, tf)\n",
    "\n",
    "    # Fix normal directions\n",
    "    signs = np.sign(np.sum(e_i * ([0,0,1]), axis=1))\n",
    "    e_i = e_i * signs[:, None]\n",
    "\n",
    "    # Compute circumcenters and axis vectors for each triangle\n",
    "    p1, p2, p3 = tv[tf[:, 0]], tv[tf[:, 1]], tv[tf[:, 2]]\n",
    "\n",
    "    ct, _, nt = circle_3pts(p1, p2, p3)\n",
    "\n",
    "    # Dual topology \n",
    "    dual_tf = tmesh.vertex_ring_faces_list()\n",
    "\n",
    "    dual_top = tmesh.dual_top()\n",
    "\n",
    "    # Create hexagonal mesh                            \n",
    "    h_pts = np.empty((len(tf), 3), dtype=np.float64)\n",
    "    \n",
    "    li = np.zeros(len(tf), dtype=np.float64)\n",
    "    \n",
    "    center = vd.Mesh((mv, mf), alpha = 0.9, c=[0.4, 0.4, 0.81])\n",
    "\n",
    "    # Intersect circumcircle axis with center mesh\n",
    "    for i in range(len(tf)):\n",
    "        # Get points on circumcircle axis\n",
    "        p0  = ct[i] - 10*nt[i]\n",
    "        p1  = ct[i] + 10*nt[i]\n",
    "\n",
    "        # Get intersection points\n",
    "        h_pts[i,:] = np.array(center.intersect_with_line(p0, p1)[0])\n",
    "\n",
    "        # Set li \n",
    "        li[i] = np.linalg.norm(h_pts[i] - ct[i])\n",
    "\n",
    "    # Get radius of spheres\n",
    "    r = np.linalg.norm(h_pts - tv[tf[:,0]], axis=1)\n",
    "\n",
    "    return tv, tf, ct, nt, li, inner_vertices, e_i, dual_tf, dual_top, r \n",
    "\n",
    "\n",
    "def visualize_data(data):\n",
    "        # # Define paths\n",
    "    dir_path = os.getcwd()\n",
    "    data_path = dir_path+\"/approximation/data/\" # data path\n",
    "\n",
    "    # Data of interest\n",
    "    k = data\n",
    "\n",
    "    # Load M mesh (centers of sphere mesh)\n",
    "    mv, mf = igl.read_triangle_mesh( os.path.join(data_path ,\"centers.obj\") ) \n",
    "\n",
    "    # Load test mesh\n",
    "    tv, tf = igl.read_triangle_mesh(os.path.join(data_path,  \"test_remeshed_\"+str(k)+\".obj\"))\n",
    "\n",
    "    # Create dual mesh\n",
    "    tmesh = Mesh()\n",
    "    tmesh.make_mesh(tv,tf)\n",
    "\n",
    "    # Get inner vertices\n",
    "    inner_vertices = tmesh.inner_vertices()\n",
    "\n",
    "    # Get vertex normals for test mesh\n",
    "    e_i = igl.per_vertex_normals(tv, tf)\n",
    "\n",
    "    # Fix normal directions\n",
    "    signs = np.sign(np.sum(e_i * ([0,0,-1]), axis=1))\n",
    "    e_i = e_i * signs[:, None]\n",
    "\n",
    "    # Compute circumcenters and axis vectors for each triangle\n",
    "    p1, p2, p3 = tv[tf[:, 0]], tv[tf[:, 1]], tv[tf[:, 2]]\n",
    "\n",
    "    ct, _, nt = circle_3pts(p1, p2, p3)\n",
    "\n",
    "    # Dual topology \n",
    "    dual_tf = tmesh.vertex_ring_faces_list()\n",
    "\n",
    "    # Create hexagonal mesh                            \n",
    "    h_pts = np.empty((len(tf), 3), dtype=np.float64)\n",
    "    center = vd.Mesh((mv, mf), alpha = 0.9, c=[0.4, 0.4, 0.81])\n",
    "\n",
    "    ps.init()\n",
    "\n",
    "    v_mesh = ps.register_surface_mesh(\"test\", tv, tf)\n",
    "\n",
    "    c_mesh = ps.register_surface_mesh(\"centers\", mv, mf)\n",
    "\n",
    "    v_mesh.add_vector_quantity(\"n_t\", -nt, defined_on = \"faces\", enabled=True, length=1.5, color=(0.1, 0.1, 0.1))\n",
    "\n",
    "    ps.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_disc(tv, tf, e_i):\n",
    "\n",
    "    # # Compute the edge vectors per each face\n",
    "    vi, vj, vk = tv[tf[:,0]], tv[tf[:,1]], tv[tf[:,2]]\n",
    "\n",
    "    # # Compute the edge vectors per each face\n",
    "    vij = vj - vi\n",
    "    vik = vk - vi\n",
    "\n",
    "    # Set up X \n",
    "    eij = e_i[tf[:,1]] - e_i[tf[:,0]]\n",
    "    eik = e_i[tf[:,2]] - e_i[tf[:,0]]\n",
    "\n",
    "    ec = np.sum( e_i[tf], axis = 1) / 3\n",
    "\n",
    "    # A = [vij, eik, ec] + [eij, vik, ec], where [ , , ] denotes determinant\n",
    "    # A = gamma11 +  gamma12\n",
    "    eikXec = np.cross(eik, ec)\n",
    "    vikXec = np.cross(vik, ec)\n",
    "\n",
    "    det1 = np.sum(vij*eikXec, axis=1)\n",
    "    det2 = np.sum(eij*vikXec, axis=1)\n",
    "\n",
    "    # b = [eij, eik, ec]  c = [vij, vik, ec]\n",
    "\n",
    "    gamma0 = np.sum(eij*eikXec, axis=1)\n",
    "    gamma2 = np.sum(vij*vikXec, axis=1)\n",
    "\n",
    "    A = det1 + det2 \n",
    "\n",
    "    return A, A**2 - 4*gamma0*gamma2\n",
    "\n",
    "def unormalize_dir(h_pts, dual, inner_vertices, tv, e_i, rad):\n",
    "    \"\"\"Input \n",
    "        h_pts: sphere centers\n",
    "        e_i: edge directions normalized\n",
    "        rad: sphere radii\n",
    "        Ouput:\n",
    "        le: unormalized edge directions\n",
    "\n",
    "    \"\"\"\n",
    "    le = np.ones_like(e_i)\n",
    "    for i in range(len(inner_vertices)):\n",
    "        # Get dual faces index\n",
    "        idx = inner_vertices[i]\n",
    "\n",
    "        # Get dual face\n",
    "        f = dual[idx]\n",
    "\n",
    "        # Get sphere centers\n",
    "        p = h_pts[f]\n",
    "\n",
    "        # Get edge direction/'\n",
    "        e = e_i[idx]\n",
    "\n",
    "        # Get radius\n",
    "        r = rad[idx]\n",
    "\n",
    "        # angle e_i with the direction to the center\n",
    "        theta = np.arccos(np.sum(e*(p - tv[idx]), axis=1))\n",
    "\n",
    "        print(theta)\n",
    "\n",
    "        # Get the lambda\n",
    "        le[idx] = 2*r*np.cos(theta)\n",
    "\n",
    "    return le\n",
    "\n",
    "def planarity_check(t1, tt1, ec):\n",
    "\n",
    "    t1_tt1 = np.cross(t1, tt1)\n",
    "    ec /= np.linalg.norm(ec, axis=1)[:, None]\n",
    "    # Check planarity\n",
    "    planar = np.sum(t1_tt1*ec, axis=1)\n",
    "\n",
    "    return planar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh Data Structure: |V| = 427, |F| = 774, |E| = 1200\n",
      " E 1: 3276.255491638389\n",
      " E 2: 687.8935750539516\n",
      " E 3: 264.26513500813024\n",
      " E 4: 73.95838665872266\n",
      " E 5: 24.437159748393533\n",
      " E 6: 9.531970277099616\n",
      " E 7: 5.10856396828844\n",
      " E 8: 2.7494577402895706\n",
      " E 9: 1.3823401309989398\n",
      " E 10: 0.6063565658872453\n",
      " E 11: 0.23896117119319715\n",
      " E 12: 0.09752814510752954\n",
      " E 13: 0.03589532385578599\n",
      " E 14: 0.014699946781568204\n",
      " E 15: 0.008096859041618651\n",
      " E 16: 0.006155615223814798\n",
      " E 17: 0.005593158858506905\n",
      " E 18: 0.005422486446473254\n",
      " E 19: 0.0053609427436505964\n",
      " E 20: 0.005329546936662221\n",
      " E 21: 0.005306499415649153\n",
      " E 22: 0.005288223943133975\n",
      " E 23: 0.005270263773547169\n",
      " E 24: 0.005252530343348193\n",
      " E 25: 0.005234930187376431\n",
      "Time per iteration:  6.55760046005249\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# X: variables [ e   | a | b | n_t  | d_i ] \n",
    "# X  size      [ 3*V | F | F | 3*F  | F   ]\n",
    "# V: Vertices\n",
    "# F: Faces\n",
    "# bf: circumcenters of the faces\n",
    "# ncf: normals of the circumcenters\n",
    "# w: weight\n",
    "\n",
    "# Init data \n",
    "tv, tf, bt, nt, df, inner_vertices, e_i, dual_tf, dual_top, r = init_test_data(1)\n",
    "\n",
    "# # Define three vertices\n",
    "# v = np.array([[-1,-1,-0.2], [1,0,0.1], [-0.8,0.1,0.2]])\n",
    "\n",
    "# # Define directions ei\n",
    "# ei = -np.array([[0,0,1], [0,0.1,0.8], [0.1,0,0.9]])\n",
    "\n",
    "# # Faces\n",
    "# f = np.array([[0,1,2]])\n",
    "\n",
    "# Compute the circumcircle\n",
    "bf, _, ncf = circle_3pts(tv[tf[:,0]], tv[tf[:,1]], tv[tf[:,2]])\n",
    "\n",
    "# Init X \n",
    "X = np.zeros(3*len(tv) + 11*len(tf))\n",
    "\n",
    "X[:3*len(tv)] = e_i.flatten()\n",
    "\n",
    "X[-len(tf):] = df\n",
    "\n",
    "\n",
    "# Init LineCong\n",
    "linecong = LineCong()\n",
    "linecong.initialize_constraint(X, len(tv), bt, nt, len(tf), dual_tf, inner_vertices, 1)\n",
    "\n",
    "torsal = Torsal()\n",
    "X = torsal.initialize_constraint(X, tv, tf, bf, ncf, 2)\n",
    "\n",
    "\n",
    "optimizer = Optimizer()\n",
    "optimizer.initialize_optimizer(X, \"LM\", 0.6)\n",
    "\n",
    "com_t = 0\n",
    "it = 25\n",
    "for _ in range(it):\n",
    "    \n",
    "    optimizer.add_constraint(torsal, tf)\n",
    "    optimizer.add_constraint(linecong, dual_tf)\n",
    "    tic = time.time()\n",
    "    optimizer.optimize()\n",
    "    toc = time.time()\n",
    "    com_t += toc - tic\n",
    "\n",
    "com_t /= it \n",
    "\n",
    "print(\"Time per iteration: \", com_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error norms tt1:  0.00046293515432985086\n",
      "nt1.t1:  0.0005846447587437482\n",
      "0.0022861469447074396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_406759/2851724301.py:52: RuntimeWarning: invalid value encountered in divide\n",
      "  att1 /= np.linalg.norm(att1, axis=1)[:, None]\n",
      "/tmp/ipykernel_406759/2851724301.py:53: RuntimeWarning: invalid value encountered in divide\n",
      "  att2 /= np.linalg.norm(att2, axis=1)[:, None]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "e, a1, b1, nt1, a2, b2, nt2, di = torsal.uncurry_variables(optimizer.X)\n",
    "\n",
    "\n",
    "vi, vj, vk = tv[tf[:,0]], tv[tf[:,1]], tv[tf[:,2]]\n",
    "\n",
    "vik = tv[tf[:,2]] - tv[tf[:,0]]\n",
    "vij = tv[tf[:,1]] - tv[tf[:,0]]\n",
    "\n",
    "e = e/np.linalg.norm(e, axis=1)[:, None]\n",
    "\n",
    "ei, ej, ek = e[tf[:,0]], e[tf[:,1]], e[tf[:,2]]\n",
    "\n",
    "vvi, vvj, vvk, _, _, _ = torsal.compute_second_env(di, e, tf)\n",
    "\n",
    "vvij = vvj - vvi\n",
    "vvik = vvk - vvi\n",
    "\n",
    "vv = vv_second(vvi, vvj, vvk, tf, len(tv))\n",
    "# vv = np.array([vvi[0], vvj[0], vvk[0]])\n",
    "\n",
    "# vvc = np.mean(vv, axis=0)\n",
    "# vc = np.mean(v, axis=0)\n",
    "\n",
    "# ec = np.array([vvc - vc])\n",
    "\n",
    "at1, at2, aa1, aa2, bb = solve_torsal(tv[tf[:,0]], tv[tf[:,1]], tv[tf[:,2]], ei, ej, ek)\n",
    "\n",
    "t1 = torsal.compute_t(a1, b1)\n",
    "t2 = torsal.compute_t(a2, b2)\n",
    "print(\"error norms tt1: \", np.linalg.norm( np.linalg.norm(t1, axis=1) - torsal.t1norms))\n",
    "t1 = t1/torsal.t1norms[:, None]\n",
    "t2 = t2/torsal.t2norms[:, None]\n",
    "\n",
    "print(\"nt1.t1: \", np.sum(nt1*t1, axis=1)@np.sum(nt1*t1, axis=1))\n",
    "\n",
    "#t1 = opt1/np.linalg.norm(opt1, axis=1)[:, None]\n",
    "#t2 = opt2/np.linalg.norm(opt2, axis=1)[:, None]\n",
    "\n",
    "tt1, _, _ = torsal.compute_tt(a1, b1, vvi, vvj, vvk)\n",
    "tt2, _, _ = torsal.compute_tt(a2, b2, vvi, vvj, vvk)\n",
    "\n",
    "\n",
    "tt1 = tt1/torsal.tt1norms[:, None]\n",
    "tt2 = tt2/torsal.tt2norms[:, None]\n",
    "\n",
    "# tt1 = optt1/np.linalg.norm(optt1, axis=1)[:, None]\n",
    "# tt2 = optt2/np.linalg.norm(optt2, axis=1)[:, None]\n",
    "\n",
    "att1 = aa1[:, None]*vvij + bb[:, None]*vvik\n",
    "att2 = aa2[:, None]*vvij + bb[:, None]*vvik\n",
    "\n",
    "att1 /= np.linalg.norm(att1, axis=1)[:, None]\n",
    "att2 /= np.linalg.norm(att2, axis=1)[:, None]\n",
    "\n",
    "#ec = (ei + ej + ek)/3\n",
    "\n",
    "vc = (vi + vj + vk)/3\n",
    "vvc = (vvi + vvj + vvk)/3\n",
    "ec = vvc - vc\n",
    "\n",
    "ec2 = torsal.compute_ec(di, e, tf)\n",
    "\n",
    "\n",
    "# Compute planarity\n",
    "planar = planarity_check(t1, tt1, ec)\n",
    "\n",
    "#filter nan values\n",
    "planar = planar[~np.isnan(planar)]\n",
    "\n",
    "print(planar@planar)\n",
    "\n",
    "# Visualization\n",
    "ps.init()\n",
    "\n",
    "ps.remove_all_structures()\n",
    "\n",
    "# Create mesh\n",
    "triangle = ps.register_surface_mesh(\"T1\", tv, tf)\n",
    "triangle2 = ps.register_surface_mesh(\"T2\", vv, tf)\n",
    "#sphere = ps.register_point_cloud(\"Sphere\", bf + di[:,None]*ncf)\n",
    "\n",
    "# Add directions\n",
    "#triangle.add_vector_quantity(\"ei\", e, defined_on='vertices', enabled=True, radius=0.005, length=2.0, color=(0.0, 0.0, 0.0))\n",
    "#triangle.add_vector_quantity(\"-ei\", -e, defined_on='vertices', enabled=True, radius=0.005, length=2.0, color=(0.0, 0.0, 0.0))\n",
    "#triangle.add_vector_quantity(\"ec\", ec, defined_on='faces', enabled=True, radius=0.0001, length=1.0, color=(0.0, 0.0, 0.0))\n",
    "\n",
    "\n",
    "# Add torsal directions\n",
    "triangle.add_vector_quantity(\"t1\",   t1, defined_on=\"faces\", enabled=True, radius=0.001, length=0.008, color=(1.0, 1.0, 1.0))\n",
    "triangle.add_vector_quantity(\"-t1\", -t1, defined_on=\"faces\", enabled=True, radius=0.001, length=0.008, color=(1.0, 1.0, 1.0))\n",
    "triangle.add_vector_quantity(\"t2\",   t2, defined_on=\"faces\", enabled=True, radius=0.001, length=0.008, color=(1.0, 1.0, 1.0))\n",
    "triangle.add_vector_quantity(\"-t2\", -t2, defined_on=\"faces\", enabled=True, radius=0.001, length=0.008, color=(1.0, 1.0, 1.0))\n",
    "\n",
    "\n",
    "\n",
    "triangle2.add_vector_quantity(\" tt1\",  tt1, defined_on=\"faces\", enabled=True, radius=0.001, length=0.008, color=(1.0, 1.0, 1.0))\n",
    "triangle2.add_vector_quantity(\"-tt1\", -tt1, defined_on=\"faces\", enabled=True, radius=0.001, length=0.008, color=(1.0, 1.0, 1.0))\n",
    "triangle2.add_vector_quantity(\" tt2\",  tt2, defined_on=\"faces\", enabled=True, radius=0.001, length=0.008, color=(1.0, 1.0, 1.0))\n",
    "triangle2.add_vector_quantity(\"-tt2\", -tt2, defined_on=\"faces\", enabled=True, radius=0.001, length=0.008, color=(1.0, 1.0, 1.0))\n",
    "# triangle.add_vector_quantity(\"at1\",  at1, defined_on=\"faces\", enabled=True, radius=0.01, length=0.01, color=(1.0, 0.0, 0.0))\n",
    "# triangle.add_vector_quantity(\"at2\",  at2, defined_on=\"faces\", enabled=True, radius=0.005, length=0.01, color=(1.0, 0.0, 0.0))\n",
    "# triangle.add_vector_quantity(\"-at1\", -at1, defined_on=\"faces\", enabled=True, radius=0.01, length=0.01, color=(1.0, 0.0, 0.0))\n",
    "# triangle.add_vector_quantity(\"-at2\", -at2, defined_on=\"faces\", enabled=True, radius=0.005, length=0.01, color=(1.0, 0.0, 0.0))\n",
    "\n",
    "# triangle2.add_vector_quantity(\"tt1\",   att1, defined_on=\"faces\", enabled=True, radius=0.01,   length=0.01, color=(0.0, 0.0, 0.0))\n",
    "# triangle2.add_vector_quantity(\"tt2\",   att2, defined_on=\"faces\", enabled=True, radius=0.01,   length=0.01, color=(0.0, 0.0, 0.0))\n",
    "# triangle2.add_vector_quantity(\"-tt1\", -att1, defined_on=\"faces\", enabled=True, radius=0.01, length=0.01, color=(0.0, 0.0, 0.0))\n",
    "# triangle2.add_vector_quantity(\"-tt2\", -att2, defined_on=\"faces\", enabled=True, radius=0.01, length=0.01, color=(0.0, 0.0, 0.0))\n",
    "\n",
    "#r = np.linalg.norm(bf + di[:,None]*ncf - v[0])\n",
    "#sphere.set_radius(r, relative=False)\n",
    "\n",
    "ps.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LC + Hyp energy Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init data \n",
    "tv, tf, bt, nt, li, inner_vertices, e_i, dual_tf, dual_top, r = init_test_data(1)\n",
    "\n",
    "# variables = [e_i | A | delta | li]; e_i direction per vertex in T and A is one per each triangle in T, same for delta \n",
    "# li is of the lenght of faces\n",
    "X = np.zeros(3*len(tv) + 3*len(tf) )\n",
    "\n",
    "# Init directions\n",
    "X[:3*len(tv)] = e_i.flatten() + np.random.normal(0, 0.1, 3*len(tv))\n",
    "X[-len(tf): ] = li\n",
    "\n",
    "\n",
    "# Init LineCong\n",
    "linecong = LineCong()\n",
    "linecong.initialize_constraint(X, len(tv), bt, nt, len(tf), dual_tf, inner_vertices, 1)\n",
    "\n",
    "# # Init Hyperbolic\n",
    "hyp = HyperbolicLC()\n",
    "X = hyp.initialize_constraint(X, tv, tf, e_i, 10, 1)\n",
    "\n",
    "# Init optimizer\n",
    "opt = Optimizer()\n",
    "opt.initialize_optimizer(X, \"LM\", 0.8)\n",
    "\n",
    "for i in range(50):\n",
    "    # Add constraints to optimizer\n",
    "    opt.add_constraint(hyp, tf)\n",
    "    opt.add_constraint(linecong, inner_vertices, dual_tf)\n",
    "\n",
    "    # Optimize\n",
    "    opt.optimize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize $e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_i = opt.X[:3*len(tv)].reshape(len(tv), 3)\n",
    "# Compute torsal directions \n",
    "_, t1, t2, cosang = torsal_dir_vec(tv, tf, e_i)\n",
    "\n",
    "# Search -1 in cosang\n",
    "idx = np.where(cosang == -1)[0]\n",
    "\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_i = opt.X[:3*len(tv)].reshape(len(tv), 3)\n",
    "e_i /= np.linalg.norm(e_i, axis=1)[:, None]\n",
    "li = opt.X[-len(tf):]\n",
    "ct = bt + li[:,None]*nt\n",
    "#le = unormalize_dir(h_pts, dual_tf, inner_vertices, tv, e_i, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.init()\n",
    "\n",
    "ps.remove_all_structures()\n",
    "\n",
    "ref      = ps.register_surface_mesh(\"Reference Mesh\", tv, tf, transparency=0.5)\n",
    "dualmesh = ps.register_surface_mesh(\"Central mesh\"  , ct, dual_top, transparency=0.5)\n",
    " \n",
    "#ref.add_vector_quantity(\"e_i\", -e_i, defined_on = \"vertices\", enabled=True, length=1.5, color=(0.1, 0.1, 0.1))\n",
    "ref.add_vector_quantity(\"axis\", nt, defined_on = \"faces\", enabled=True, length=1.5, color=(0.1, 0.1, 0.1))\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export points of evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of interest\n",
    "data = 1\n",
    " # Export vertices and barycenters\n",
    "np.savetxt(out_path+\"vertices_\"+str(data)+\".dat\", tv)\n",
    "\n",
    "bar = np.mean(tv[tf], axis=1)\n",
    "np.savetxt(out_path+\"barycenters_\"+str(data)+\".dat\", bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Analytic values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytic torsal directions\n",
    "at1 = np.loadtxt(math_path+\"tdir1.dat\")\n",
    "at2 = np.loadtxt(math_path+\"tdir2.dat\")\n",
    "edir = np.loadtxt(math_path+\"edir.dat\")\n",
    "\n",
    "# Check dimensions\n",
    "assert len(edir) == len(e_i), \"Not same dimensions in e_i\"\n",
    "assert len(at1) == len(tf), \"Not same dimensions in at1\"\n",
    "assert len(at2) == len(tf), \"Not same dimensions in at1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute errors of torsal directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_angles_error(t1,t2, at1, at2):\n",
    "    \"\"\"\n",
    "        Function to compute the angle error between two torsal directions.\n",
    "    \"\"\"\n",
    "\n",
    "    # if t1 and t2 are zero vectors, then exclude\n",
    "    idx = np.where(np.linalg.norm(t1, axis=1) != 0)[0]\n",
    "\n",
    "    # Compute angle between t1 at1\n",
    "    ang11 = np.arccos(np.sum(abs(t1*at1), axis=1))\n",
    "\n",
    "    # Compute angle between t1 at2\n",
    "    ang12 = np.arccos(np.sum(abs(t1*at2), axis=1))\n",
    "    \n",
    "    # Compute angle between t2 at1\n",
    "    ang21 = np.arccos(np.sum(abs(t2*at1), axis=1))\n",
    "\n",
    "    # Compute angle between t2 at2\n",
    "    ang22 = np.arccos(np.sum(abs(t2*at2), axis=1))\n",
    "\n",
    "    # Compute error as min( 2*(ang11 + ang22)/pi,  2*(ang12 + ang21)/pi)\n",
    "    error = np.minimum(2*(ang11 + ang22)/np.pi, 2*(ang12 + ang21)/np.pi)\n",
    "\n",
    "\n",
    "    return error, idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute torsal directions \n",
    "_, t1, t2, _ = torsal_dir_vec(tv, tf, e_i)\n",
    "\n",
    "# Compute error as the angle between the analytic and the computed torsal directions\n",
    "errang, valid_faces = compute_angles_error(t1,t2, at1, at2)\n",
    "\n",
    "err3 = np.zeros(len(tv))\n",
    "# Compute error as the angle between the analytic and the computed edge directions\n",
    "err3[inner_vertices] = np.arccos(np.sum(e_i[inner_vertices]*edir[inner_vertices], axis=1)) * 180/np.pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show histograms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot two histograms in the same figure but separated\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "# Plot histogram for torsal directions\n",
    "ax1.hist(errang, bins=20)\n",
    "ax1.set_xlabel(\"Angle error\")\n",
    "ax1.set_ylabel(\"Frequency\")\n",
    "ax1.set_title(\"Torsal directions\")\n",
    "# Plot histogram for edge directions\n",
    "ax2.hist(err3, bins=20)\n",
    "ax2.set_xlabel(\"Angle error (deg)\")\n",
    "ax2.set_ylabel(\"Frequency\")\n",
    "ax2.set_title(\"Edge directions\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Torsal directions and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torsal vis settings\n",
    "\n",
    "\n",
    "# Init polyscope\n",
    "ps.init()\n",
    "\n",
    "# Create mesh\n",
    "mesh = ps.register_surface_mesh(\"mesh\", tv, tf)\n",
    "\n",
    "# Add cmap mesh\n",
    "mesh.add_scalar_quantity(\"errang\", errang, defined_on = \"faces\", enabled=True, cmap=\"coolwarm\")\n",
    "\n",
    "# color map vertices with edges error\n",
    "mesh.add_scalar_quantity(\"err3\", err3, defined_on = \"vertices\", enabled=True, cmap=\"coolwarm\")\n",
    "\n",
    "# Add torsal directions\n",
    "mesh.add_vector_quantity(\" at1 \", at1, defined_on ='faces', enabled=True, radius=0.001, length=0.005, color=(0.0, 0.0, 0.0))\n",
    "mesh.add_vector_quantity(\"-at1\", -at1, defined_on ='faces', enabled=True, radius=0.001, length=0.005, color=(0.0, 0.0, 0.0))\n",
    "mesh.add_vector_quantity(\" at2 \", at2, defined_on ='faces', enabled=True, radius=0.001, length=0.005, color=(0.0, 0.0, 0.0))\n",
    "mesh.add_vector_quantity(\"-at2\", -at2, defined_on ='faces', enabled=True, radius=0.001, length=0.005, color=(0.0, 0.0, 0.0))\n",
    "\n",
    "mesh.add_vector_quantity(\"t1 \",  t1, defined_on ='faces', enabled=True, radius=0.001, length=0.005, color=(1.0, 0.0, 0.0))\n",
    "mesh.add_vector_quantity(\"-t1\", -t1, defined_on ='faces', enabled=True, radius=0.001, length=0.005, color=(1.0, 0.0, 0.0))\n",
    "mesh.add_vector_quantity(\"t2 \",  t2, defined_on ='faces', enabled=True, radius=0.001, length=0.005, color=(1.0, 0.0, 0.0))\n",
    "mesh.add_vector_quantity(\"-t2\", -t2, defined_on ='faces', enabled=True, radius=0.001, length=0.005, color=(1.0, 0.0, 0.0))\n",
    "\n",
    "# Visualize directions\n",
    "\n",
    "# mesh.add_vector_quantity(\"e_i\", e_i, defined_on='vertices', enabled=True, radius=0.001, length=2.0, color=(0.0, 0.0, 0.0))\n",
    "# # mesh.add_vector_quantity(\"ae_i\", edir, defined_on='vertices', enabled=True, radius=0.001, length=2.0, color=(1.0, 1.0, 1.0))\n",
    "\n",
    "# # Create second mesh of envelope\n",
    "# mesh2 = ps.register_surface_mesh(\"mesh2\", tv + 3*e_i, tf)\n",
    "\n",
    "# mesh3 = ps.register_surface_mesh(\"mesh3\", tv + 3.01*edir, tf)\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_torsal_direction(data, tv, tf, e_i):\n",
    "\n",
    "    # Data \n",
    "    k = data\n",
    "\n",
    "    # Create file for positions\n",
    "    pos = open(os.path.join( out_path, \"torsal_pos_\"+str(k)+\".dat\"), \"w\")\n",
    "    # Create file for torsal directions\n",
    "    tdir = open(os.path.join( out_path, \"torsal_dir_\"+str(k)+\".dat\"), \"w\")\n",
    "    # Create file to store the ids of the inner faces\n",
    "    f_if = open(os.path.join( out_path, \"inner_faces_\"+str(k)+\".dat\"), \"w\")\n",
    "\n",
    "    # Compute torsal directions\n",
    "    barycenters, t1, t2, cos_tors = torsal_dir_vec(tv, tf, e_i)\n",
    "    \n",
    "    # Get inner faces\n",
    "    t_mesh = Mesh()\n",
    "    t_mesh.make_mesh(tv, tf)\n",
    "    inner_faces = t_mesh.inner_faces()\n",
    "\n",
    "    for ii in range(len(inner_faces)):\n",
    "        i = inner_faces[ii]\n",
    "        pos.write(str(barycenters[i][0]) + \" \" + str(barycenters[i][1]) + \" \" + str(barycenters[i][2]) + \"\\n\")\n",
    "        tdir.write(str(t1[i][0]) + \" \" + str(t1[i][1]) + \" \" + str(t1[i][2]) + \" \" + str(t2[i][0]) + \" \" + str(t2[i][1]) + \" \" + str(t2[i][2]) + \"\\n\")\n",
    "        f_if.write(str(i) + \"\\n\")\n",
    "\n",
    "\n",
    "    pos.close()\n",
    "    print(\"Positions file created\")\n",
    "    tdir.close()\n",
    "    print(\"Torsal dir files created\")\n",
    "    f_if.close()\n",
    "    print(\"Inner faces file created\")\n",
    "\n",
    "def export_toral_data_testing(data, tv, tf, e_i, list_bad_faces):\n",
    "\n",
    "    # Data\n",
    "    k = data \n",
    "\n",
    "    # Compute torsal directions\n",
    "    _, t1, t2, _ = torsal_dir_vec(tv, tf, e_i)\n",
    "\n",
    "    # Create data frame\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Create a table with e_i[tf[list_bad_faces]], tv[tf[list_bad_Faces]], t1[list_bad_faces], t2[list_bad_faces]\n",
    "    df[\"e_i\"] = e_i[tf[list_bad_faces]].tolist()\n",
    "    df[\"tv\"] = tv[tf[list_bad_faces]].tolist()\n",
    "    df[\"t1\"] = t1[list_bad_faces].tolist()\n",
    "    df[\"t2\"] = t2[list_bad_faces].tolist()\n",
    "\n",
    "    # Export df to csv\n",
    "    df.to_csv(os.path.join( out_path, \"bf_data_\"+str(k)+\".csv\"), index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_torsal_direction(4, tv, tf, e_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_toral_data_testing(4, tv, tf, e_i, np.array([847,833,806,776,770,767,733,721,688,571]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Torsal Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three vertices\n",
    "v = np.array([[-1,-1,-0.2], [1,0,0.1], [-0.8,0.1,0.2]])\n",
    "\n",
    "# Define directions ei\n",
    "ei = -np.array([[0,0,1], [0,0.1,0.8], [0.1,0,0.9]])\n",
    "# Normalize ei\n",
    "ei /= np.linalg.norm(ei, axis=1)[:, None]\n",
    "\n",
    "# Compute the circumcircle \n",
    "c, cr, n = circle_3pts(v[0], v[1], v[2])\n",
    "\n",
    "# Define a distance from the circumcenter to the center of a sphere\n",
    "di = 2\n",
    "\n",
    "# sphere center\n",
    "sc = c + di*n\n",
    "\n",
    "# Compute radius of the sphere\n",
    "r = np.linalg.norm(v[0] - sc)\n",
    "\n",
    "# directions vertices to center\n",
    "dc = sc - v\n",
    "dc /= np.linalg.norm(dc, axis=1)[:, None] # normalize\n",
    "\n",
    "dc2 = sc - v\n",
    "\n",
    "# Second envelope points\n",
    "angles = np.sum(dc*ei, axis=1)\n",
    "\n",
    "# ec * dc2 \n",
    "dotec = np.sum(ei*dc2, axis=1)\n",
    "\n",
    "# Compute the lambdas\n",
    "l = 2*r*angles\n",
    "l2 = 2*dotec\n",
    "\n",
    "# New points\n",
    "u  = v + l[:, None]*ei\n",
    "u2 = v + l2[:, None]*ei\n",
    "\n",
    "print(f\"u:{u}\\nu2:{u2}\")\n",
    "\n",
    "# Compute A v = u\n",
    "\n",
    "A = u.T@np.linalg.inv(v.T)\n",
    "\n",
    "vij  = v[1] - v[0]\n",
    "vik  = v[2] - v[0]\n",
    "\n",
    "uij = u[1] - u[0]\n",
    "uik = u[2] - u[0]\n",
    "\n",
    "\n",
    "t1  = 2*vij + 3*vik \n",
    "ut1 = 2*uij + 3*uik \n",
    "# Print distance u to sc\n",
    "print(A@t1)\n",
    "print(ut1)\n",
    "\n",
    "# Baricenter\n",
    "vc = np.mean(v, axis=0)\n",
    "uc = np.mean(u, axis=0)\n",
    "\n",
    "ec = uc - vc\n",
    "ec = ec/np.linalg.norm(ec)\n",
    "ec2 = np.mean(ei, axis=0)\n",
    "ec2 = ec2/np.linalg.norm(ec2)\n",
    "\n",
    "print(f\"ec : {ec}\\nec2: {ec2}\")\n",
    "\n",
    "# Visualization\n",
    "ps.init()\n",
    "\n",
    "ps.remove_all_structures()\n",
    "\n",
    "# Create mesh\n",
    "triangle = ps.register_surface_mesh(\"T1\", v, np.array([[0,1,2]]))\n",
    "triangle2 = ps.register_surface_mesh(\"T2\", u, np.array([[0,1,2]]))\n",
    "sphere = ps.register_point_cloud(\"Sphere\", sc)\n",
    "sphere.set_radius(r, relative=False)\n",
    "\n",
    "# Add directions\n",
    "triangle.add_vector_quantity(\"ei\", ei, defined_on='vertices', enabled=True, radius=0.005, length=2.0, color=(0.0, 0.0, 0.0))\n",
    "triangle.add_vector_quantity(\"t1\", np.array([t1]), defined_on=\"faces\", enabled=True, radius=0.01, length=0.5, color=(0.0, 0.0, 0.0))\n",
    "triangle.add_vector_quantity(\"ec\", np.array([ec]), defined_on=\"faces\", enabled=True, radius=0.001, length=2.5, color=(0.8, 0.0, 0.0))\n",
    "triangle.add_vector_quantity(\"ec2\", np.array([ec2]), defined_on=\"faces\", enabled=True, radius=0.001, length=2.5, color=(0.0, 0.0, 0.8))\n",
    "\n",
    "triangle2.add_vector_quantity(\"at1\", np.array([ut1]), defined_on=\"faces\", enabled=True, radius=0.01, length=0.5, color=(0.0, 0.0, 0.0))\n",
    "\n",
    "ps.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hananJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
